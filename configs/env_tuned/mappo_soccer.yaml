algo: "mappo"
env_id: "Soccer"

actor_lr: 5.0e-4
critic_lr: 5.0e-4
entropy_coef: 0.01
gamma: 0.99
gae_lambda: 0.95
clip_param: 0.2
ppo_epoch: 5
num_mini_batch: 32
use_clipped_value_loss: True

hidden_sizes: [128, 128]
state_dependent_std: False
use_max_grad_norm: True
max_grad_norm: 10.
use_reward_norm: True

shared_policy: False
shared_critic: True

# PPO epochs per update
n_steps: 2048

use_role_id: False

teams: # list of lists of agent indices  (global order)
  - [0, 2] # team 0  → agent-0 of brain-0  +  agent-0 of brain-1
  - [1, 3] # team 1  → agent-1 of brain-0  +  agent-1 of brain-1

# Competitive evaluation settings
zerosum: True
competitive_eval_episodes: 5
max_model_snapshots: 10

eval_interval: 10000
log_interval: 1000
max_steps: 1000000
